\documentclass{article}

\usepackage[utf8]{inputenc}
\usepackage{amsmath}
\usepackage{graphicx}
\usepackage[hidelinks]{hyperref}
\usepackage{hyperref}
\usepackage[backend=biber, style=numeric]{biblatex}
\addbibresource{refs.bib}

\title{Portfolio Specification}
\author{Jack Foley | C00274246 \\[1cm]Supervisor: Greg Doyle}
\date{\today}

\begin{document}

\maketitle
\newpage

\tableofcontents

\newpage

\section{Introduction}
This is a technical specification document for the Data Science (DS) and Machine Learning (ML) 
module run by Greg Doyle. As a part of the module, we, the students, are required to 
create this document to plan the various machine learning and data science projects 
that we will be working on throughout the first semester. By the end of the semester
we are expected to have completed all the projects defined in this document and then
present them to the class. This document will be used as a reference throughout the
semester to ensure that we are on track to complete the projects on time. 

\section{Portfolio Content}
The portfolio will be a simple static website that will contain various information about myself, including links to my CV, contact information, as well as projects 
that I have completed throughout the semester. The website will be built using HTML, CSS, and JavaScript, if needed. The projects will be displayed on the website one by one.

The headings for the portfolio will be as follows:
\begin{itemize}
    \item About me
    \item Employment
    \item Projects
    \item Education
    \item Contact Links
\end{itemize}

\section{Available Hardware}
ML can use up a lot of computational power, so it is important to have access to machines that are capable enough for running ML tasks. Below is a list of the 
hardware that I have access to for the duration of the semester. What piece of hardware I use will depend on the task at hand.
\begin{itemize}
    \item Personal Laptop | Lenovo Thinkpad E16 Gen 1
    \begin{itemize}
        \item \textbf{CPU}: Intel Core i5-13420H (8C/16T)
        \item \textbf{Discrete GPU}: N/A
        \item \textbf{Memory}: 24GB DDR4
    \end{itemize}
    \item Desktop | Custom Build
    \begin{itemize}
        \item \textbf{CPU}: AMD Ryzen 7 5800X3D (8C/16T)
        \item \textbf{Discrete GPU}: Nvidia RTX 4070
        \item \textbf{Memory}: 32GB DDR4
        \item \textbf{Additional Note}: I have full remote access to this machine, therefore it will be used for any tasks that can use a GPU.
    \end{itemize}
\end{itemize} 

\section{Ideas}
\subsection{Sea Level Prediction}

\begin{itemize}
    \item \textbf{Brief Description:} Predict future sea levels using a polynomial regression algorithm.
    \item \textbf{Dataset Source:} \href{https://www.kaggle.com/datasets/kkhandekar/global-sea-level-1993-2021}{Click here} 
    \item \textbf{Technologies:}
    \begin{itemize}
        \item Python - Used for writing ML algorithms
        \item Pandas - Used for data processing
        \item Numpy - Used for any mathematics
        \item Matplotlib - Used for plotting data
        \item Scikit-learn - Used for ML models
        \item Jupyter Notebook - Used for running the code / organisation
        \item ML Model: Polynomial regression
    \end{itemize}
    \item \textbf{Detailed Description:} In a world where global warming is steadily heating up the planet, a side affect is the rise of the sea levels across the globe. 
    It is important that we have a prediction of where the sea levels will end up in the future so that we can prepare for the worst. To do this, we can use a polynomial 
    regression algorithm to predict future sea levels. The dataset will have to be cleaned and preprocessed before we can use it to train the model.
    \item \textbf{Hardware:} The hardware I will be using will be my laptop, it is sufficient for this task since it is not too computationally intensive. 
\end{itemize}

\subsection{Titanic Death Prediction}

\begin{itemize}
    \item \textbf{Brief Description:} Predict whether a passenger on the Titanic survived or not.
    \item \textbf{Dataset Source:} \href{https://web.stanford.edu/class/archive/cs/cs109/cs109.1166/problem12.html}{Click here}
    \item \textbf{Technologies:}
    \begin{itemize}
        \item Python - Used for writing ML algorithms
        \item Pandas - Used for data processing
        \item Numpy - Used for any mathematics
        \item Matplotlib - Used for plotting data
        \item Scikit-learn - Used for ML models
        \item Jupyter Notebook - Used for running the code / organisation
        \item ML Model: Decision Tree
    \end{itemize}
    \item \textbf{Detailed Description:} The Titanic was a ship that sank in 1912 after hitting an iceberg. The ship was carrying 2,224 passengers and crew, of which 1,502 died. 
    The Titanic dataset is a common task done as a beginner friendly ML exercise. The dataset contains various information about the passengers such as age, class, if they had children, etc.
    Using a decision tree model, we can predict whether a passenger survived or not. Dataset cleaning and preprocessing will be required before we can train the model.
    \item \textbf{Hardware:} The hardware I will be using will be my laptop, it is sufficient for this task since it is not too computationally intensive.
\end{itemize}

\subsection{Inflation Prediction using CPI Data}

\begin{itemize}
    \item \textbf{Brief Description:} Inflation prediction using Consumer Price Index (CPI) data and a linear regression model. 
    \item \textbf{Dataset Source:} \href{https://data.gov.ie/dataset/cpm03-consumer-price-index}{Click here}
    \item \textbf{Technologies:}
    \begin{itemize}
        \item Python - Used for writing ML algorithms
        \item Pandas - Used for data processing
        \item Numpy - Used for any mathematics
        \item Matplotlib - Used for plotting data
        \item Scikit-learn - Used for ML models
        \item Jupyter Notebook - Used for running the code / organisation
        \item ML Model: Linear Regression
    \end{itemize}
    \item \textbf{Detailed Description:} Inflation is the rate at which the general level of prices for goods and services is rising, and subsequently, purchasing power is falling. 
    It is important to have a prediction of where inflation will end up in the future so that we can prepare for the worst. To do this, we can use a linear regression algorithm to predict future inflation.
    The dataset will have to be cleaned and preprocessed before we can use it to train the model since it has some missing data and/or outliers.
    \item \textbf{Hardware:} The hardware I will be using will be my laptop, it is sufficient for this task since it is not computationally intensive.
\end{itemize}

\subsection{OCR on Chars74k Dataset to Predict Characters}

\begin{itemize}
    \item \textbf{Brief Description:} Perform Optical Character Recognition (OCR) on the Chars74k dataset using Deep Learning and CNNs.
    \item \textbf{Dataset Source:} \href{https://web.stanford.edu/class/archive/cs/cs109/cs109.1166/problem12.html}{Click here}
    \item \textbf{Technologies:}
    \begin{itemize}
        \item Python - Used for writing ML algorithms
        \item Pandas - Used for data processing
        \item Numpy - Used for any mathematics
        \item Matplotlib - Used for plotting data
        \item Scikit-learn - Used for ML models
        \item Jupyter Notebook - Used for running the code / organisation
        \item TensorFlow - Used for deep learning
        \item Keras - Used for building the CNN
        \item ML Model: CNN
    \end{itemize}
    \item \textbf{Detailed Description:} Optical Character Recognition (OCR) is the recognition of printed or written text characters by a computer.
    The Chars74k dataset is a dataset that contains 74,000 images of handwritten characters. Using a Convolutional Neural Network (CNN), we can predict what character is in the image.
    \item \textbf{Hardware:} The hardware I will be using will be my desktop, it is sufficient for this task since it is computationally intensive and requires a GPU.
\end{itemize}

\section{Deployment}    
Since the portfolio is a website, it will have to be deployed somewhere. The first option is a Vercel deployment, 
which is a platform that allows you to deploy static websites for free using the Hobbyist plan. 
The second option is a GitHub Pages deployment, which is also a platform that allows you to deploy static websites for free. 
Any of the actual ML projects will be on Google Colab, which will allow users to run the code without having to install any dependencies.

\section{GDPR}
It is important that the datasets used in the projects are GDPR compliant. This means that the data must be anonymised and/or pseudonymised.
This will be done in the preprocessing stage of the projects.

\end{document}